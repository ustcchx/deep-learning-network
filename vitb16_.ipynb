{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.191472Z",
     "start_time": "2023-12-29T13:54:47.882388Z"
    },
    "id": "STsK2PeIFGE_"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import flatten\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.optim as opt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.197193Z",
     "start_time": "2023-12-29T13:54:51.192475Z"
    },
    "id": "FiKZIqERFnsh"
   },
   "outputs": [],
   "source": [
    "class patch_embedding(nn.Module) :\n",
    "  def __init__(self, img_size=224, inchannels=3) :\n",
    "    super(patch_embedding,self).__init__()\n",
    "    self.patch_conv2d = nn.Conv2d(in_channels=inchannels, out_channels=768, stride=16, kernel_size=16)\n",
    "    self.class_token = nn.Parameter(torch.randn(1,768))\n",
    "    self.position_token = nn.Parameter(torch.zeros(197,768))\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "  def forward(self, x) :#x(1,3,224,224)\n",
    "    x = self.patch_conv2d(x) #x(1,768,14,14)\n",
    "    x = flatten(x, start_dim=2, end_dim=3) #x(1,768,196)\n",
    "    x = x.transpose(1,2) #exchange dim, x(1,196,768)\n",
    "    class_tokens = self.class_token.expand(x.shape[0],-1,-1)\n",
    "    x = torch.cat((class_tokens,x),dim=1)# x(1,197,768)\n",
    "    x = x + self.position_token\n",
    "    x = self.dropout(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.206843Z",
     "start_time": "2023-12-29T13:54:51.202961Z"
    },
    "id": "9H1dxk0dYnv9"
   },
   "outputs": [],
   "source": [
    "class MLP_block(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(MLP_block,self).__init__()\n",
    "    self.MLP_linear_1 = nn.Linear(in_features=768,out_features=3072)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout_1 = nn.Dropout(0.1)\n",
    "    self.MLP_linear_2 = nn.Linear(in_features=3072,out_features=768)\n",
    "    self.dropout_2 = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self,x) :\n",
    "    x = self.MLP_linear_1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.dropout_1(x)\n",
    "    x = self.MLP_linear_2(x)\n",
    "    x = self.dropout_2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.213995Z",
     "start_time": "2023-12-29T13:54:51.207840Z"
    },
    "id": "Wj3iFGEyokhu"
   },
   "outputs": [],
   "source": [
    "class multi_head_att(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(multi_head_att,self).__init__()\n",
    "    self.q = nn.Linear(768,768)\n",
    "    self.k = nn.Linear(768,768)\n",
    "    self.v = nn.Linear(768,768)\n",
    "    self.out = nn.Linear(768,768)\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "  def transpose(self,x) :#x(1,197,768)\n",
    "    x = x.reshape(x.size()[0:2]+(12,64)) #x(1,197,12,64)\n",
    "    x = x.permute(0,2,1,3) #x(1,12,197,64)\n",
    "    return x\n",
    "\n",
    "  def forward(self,x) :\n",
    "    all_q = self.q(x)\n",
    "    all_v = self.v(x)\n",
    "    all_k = self.k(x)\n",
    "    all_q_trans = self.transpose(all_q)\n",
    "    all_v_trans = self.transpose(all_v)\n",
    "    all_k_trans = self.transpose(all_k)\n",
    "    att_sc = torch.matmul(all_q_trans,all_k_trans.transpose(-1,-2))\n",
    "    att_sc = att_sc/8 #torch.sqrt(64)\n",
    "    att_sc = self.softmax(att_sc)\n",
    "    context_layer = torch.matmul(att_sc,all_v_trans) #(1,12,197,64)\n",
    "    context_layer = context_layer.permute(0,2,1,3) #(1,197,12,64)\n",
    "    new_shape = context_layer.size()[0:2]+(768,) #(1,197,768)\n",
    "    context_layer = context_layer.reshape(*new_shape)\n",
    "    out = self.out(context_layer)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.219141Z",
     "start_time": "2023-12-29T13:54:51.214997Z"
    },
    "id": "eAJHlJZUfME9"
   },
   "outputs": [],
   "source": [
    "class encoder_block(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(encoder_block,self).__init__()\n",
    "    self.layernorm_1 = nn.LayerNorm(normalized_shape=(197,768))\n",
    "    self.layernorm_2 = nn.LayerNorm(normalized_shape=(197,768))\n",
    "    self.mul_att = multi_head_att()\n",
    "    self.dropout_1 = nn.Dropout(0.1)\n",
    "    self.dropout_2 = nn.Dropout(0.1)\n",
    "    self.MLP = MLP_block()\n",
    "\n",
    "  def forward(self,x) :\n",
    "    y = self.layernorm_1(x)\n",
    "    y = self.mul_att(y)\n",
    "    y = self.dropout_1(y)\n",
    "    x = y+x\n",
    "    y = self.layernorm_2(x)\n",
    "    y = self.MLP(y)\n",
    "    y = self.dropout_2(y)\n",
    "    x = y+x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.224995Z",
     "start_time": "2023-12-29T13:54:51.220143Z"
    },
    "id": "Oki3IP2eBQl5"
   },
   "outputs": [],
   "source": [
    "class vit_transformer(nn.Module) :\n",
    "  def __init__(self,nums_classes:int=2) :\n",
    "    super(vit_transformer,self).__init__()\n",
    "    self.encoder_blocks = self.__make_layer()\n",
    "    self.start_blocks = patch_embedding()\n",
    "    self.layernorm = nn.LayerNorm(normalized_shape=(197,768))\n",
    "    self.linear_out = nn.Linear(in_features=100,out_features=nums_classes)\n",
    "    self.pre_logits_linear = nn.Linear(in_features=768,out_features=100)\n",
    "    self.pre_logits_tanh = nn.Tanh()\n",
    "\n",
    "  def __make_layer(self,nums_encoder_block=12) :\n",
    "    layers = []\n",
    "    for _ in range(nums_encoder_block) :\n",
    "      layers.append(encoder_block())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self,x) :\n",
    "    x = self.start_blocks(x)\n",
    "    x = self.encoder_blocks(x)\n",
    "    x = self.layernorm(x)\n",
    "    x = x[:,0,:]\n",
    "    x = self.pre_logits_linear(x)\n",
    "    x = self.pre_logits_tanh(x)\n",
    "    x = self.linear_out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.229717Z",
     "start_time": "2023-12-29T13:54:51.226997Z"
    },
    "id": "KeuRCRZ1mu-C"
   },
   "outputs": [],
   "source": [
    "def transform_jpg(path:str) :\n",
    "  img = Image.open(path).convert(\"RGB\")\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(p=0.5),\n",
    "      transforms.Compose([transforms.RandomCrop(224, padding=4)]),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "  img = transform(img).float()\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.348428Z",
     "start_time": "2023-12-29T13:54:51.230718Z"
    },
    "id": "9T-3eN1D4gm_"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(\"data\",\"train\")\n",
    "test_dir = os.path.join(\"data\",\"test\")\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225] \n",
    "train_augs = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.Compose([transforms.RandomCrop(224, padding=4)]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "test_augs = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "train_set = datasets.ImageFolder(train_dir, transform=train_augs)\n",
    "test_set = datasets.ImageFolder(test_dir, transform=test_augs)\n",
    "batch_size = 32\n",
    "train_iter = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_iter = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:54:51.442355Z",
     "start_time": "2023-12-29T13:54:51.349429Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1739,
     "status": "ok",
     "timestamp": 1703825476576,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "krOuVrgfZloP",
    "outputId": "ffce9a23-bedf-44d3-dffb-ccbde0fa5083",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "lr = 0.00005\n",
    "model = vit_transformer()\n",
    "model.to(device)\n",
    "optimizer = opt.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)  # 每1个epoch学习率乘以0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:54:51.318Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1703783427339,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "TY1CSGiCZiUc",
    "outputId": "946f6ec3-c0de-4012-a6d6-9ea3b4c1878f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "101\n",
      "201\n",
      "301\n",
      "401\n",
      "501\n",
      "601\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)  # 定义损失函数\n",
    "criterion = criterion.to(device)\n",
    "num_epochs = 40  # 设置训练轮数\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()  # 设置模型为训练模式\n",
    "  running_loss = 0.0\n",
    "  for i,(inputs,labels) in enumerate(train_iter):\n",
    "      if i%100 == 1 :\n",
    "          print(i)  \n",
    "      labels2d = torch.tensor([([0,1] if labels[k]==1 else [1,0]) for k in range(len(labels))]).float()\n",
    "      inputs, labels2d = inputs.to(device), labels2d.to(device)  # 将输入和标签移至设备\n",
    "      optimizer.zero_grad()  # 清零梯度\n",
    "      outputs = model(inputs)  # 前向传播\n",
    "      loss = criterion(outputs, labels2d).to(device)  # 计算损失\n",
    "      loss.backward()  # 反向传播:\n",
    "      optimizer.step()  # 更新模型参数\n",
    "      running_loss += loss.item()  # 累加损失\n",
    "  # for name,s in model.named_parameters() :\n",
    "  #     if \"class\" in name :\n",
    "  #         print(s)\n",
    "  scheduler.step()\n",
    "  model.eval()\n",
    "  acc = 0\n",
    "  for j,(inputs,labels) in enumerate(test_iter):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)  # 将输入和标签移至设备\n",
    "    outputs = model(inputs)\n",
    "    #print(outputs)\n",
    "    acc += (torch.argmax(outputs,dim=1)==labels).sum()\n",
    "  print(int(acc)/len(test_set),running_loss)\n",
    "  print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T14:06:52.839673Z",
     "start_time": "2023-12-29T14:06:52.837456Z"
    }
   },
   "outputs": [],
   "source": [
    "temp=torch.randn(2,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(temp.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.2070e+00, -1.4405e+00,  1.0942e+00,  ..., -1.7945e+00,\n",
       "           -1.1536e+00, -5.9671e-01],\n",
       "          [ 4.0849e-01,  9.6268e-01,  4.1731e-01,  ...,  9.8890e-01,\n",
       "            2.1587e-01, -6.0898e-01],\n",
       "          [-8.4422e-01, -1.4986e+00, -1.5211e+00,  ...,  7.7938e-01,\n",
       "           -2.9462e-01, -1.0463e-01],\n",
       "          ...,\n",
       "          [-8.0904e-01,  1.7094e-01, -4.3821e-01,  ..., -8.0661e-01,\n",
       "            4.2611e-03, -8.7575e-01],\n",
       "          [ 4.5484e-01, -1.5969e+00, -4.4237e-01,  ...,  2.2141e+00,\n",
       "           -2.5057e-01,  1.6764e+00],\n",
       "          [-5.8072e-01, -1.6755e+00, -6.0562e-01,  ..., -1.4687e+00,\n",
       "           -1.7963e+00,  6.8623e-01]],\n",
       "\n",
       "         [[-1.3426e+00,  8.0804e-02,  1.1976e+00,  ...,  2.6589e-01,\n",
       "            6.2099e-01, -5.5215e-01],\n",
       "          [-1.6689e+00,  5.5142e-01,  2.0722e-01,  ...,  1.1988e+00,\n",
       "            2.1333e+00, -1.2328e+00],\n",
       "          [-1.0650e+00, -1.3250e+00,  1.3441e+00,  ..., -7.4189e-01,\n",
       "           -1.0795e+00, -1.3313e-01],\n",
       "          ...,\n",
       "          [-9.2385e-01,  1.4236e+00, -4.4880e-01,  ..., -8.8064e-01,\n",
       "           -1.1993e-01,  3.0881e-01],\n",
       "          [-6.1854e-01, -2.8074e-01, -1.8946e+00,  ..., -5.0528e-01,\n",
       "            8.1744e-02,  9.8083e-03],\n",
       "          [ 5.1411e-02,  5.4337e-01,  1.3763e+00,  ..., -2.1631e+00,\n",
       "           -1.9824e-01, -1.7959e+00]],\n",
       "\n",
       "         [[-4.2597e-01, -1.7934e-01,  1.8863e-01,  ..., -2.2871e-01,\n",
       "           -1.5026e-01,  2.5108e+00],\n",
       "          [-9.8160e-02,  1.2975e+00,  1.2263e-01,  ..., -5.0763e-01,\n",
       "            4.6333e-01,  1.5387e-01],\n",
       "          [-3.8303e-01,  7.9120e-01,  1.1681e-01,  ..., -1.2589e+00,\n",
       "            1.1525e+00,  1.5473e+00],\n",
       "          ...,\n",
       "          [ 5.7914e-01,  9.3514e-01,  3.6050e-01,  ..., -8.4883e-01,\n",
       "           -3.7616e-01, -1.0646e+00],\n",
       "          [-1.6227e+00, -2.7800e-01, -2.5337e+00,  ...,  1.9332e+00,\n",
       "            8.7016e-01, -2.8548e-01],\n",
       "          [ 6.9709e-01,  5.1459e-01,  7.7273e-01,  ...,  1.0669e-01,\n",
       "           -1.8894e+00,  5.6098e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1458e+00,  1.8251e+00,  2.3598e+00,  ..., -9.1130e-01,\n",
       "           -3.6361e+00, -7.2427e-01],\n",
       "          [-1.1851e-01, -6.2872e-01,  1.5622e+00,  ..., -5.6084e-01,\n",
       "           -5.3386e-01,  1.4601e+00],\n",
       "          [-1.9846e+00, -9.3218e-01, -1.3869e+00,  ..., -8.4940e-01,\n",
       "            1.9710e+00, -2.0945e-01],\n",
       "          ...,\n",
       "          [ 1.1348e+00,  7.2446e-01, -7.1384e-02,  ..., -1.3483e+00,\n",
       "            8.5534e-01, -1.7590e-01],\n",
       "          [-2.9904e-02, -3.1404e-01,  1.4949e+00,  ...,  1.7539e+00,\n",
       "            7.9236e-01, -8.3233e-01],\n",
       "          [ 2.4134e-02,  1.1634e+00, -9.5354e-01,  ...,  6.7977e-01,\n",
       "            1.1698e+00,  1.4964e-01]],\n",
       "\n",
       "         [[-8.4882e-01,  2.0193e+00, -2.6747e+00,  ..., -7.0012e-01,\n",
       "           -5.1579e-01,  9.6016e-01],\n",
       "          [ 1.1495e+00, -1.8009e-01, -7.9971e-01,  ...,  7.8618e-01,\n",
       "            1.0691e+00, -1.3234e+00],\n",
       "          [-1.0644e+00, -1.2675e+00, -6.1492e-01,  ...,  1.4816e+00,\n",
       "            1.7395e+00,  1.5328e+00],\n",
       "          ...,\n",
       "          [ 2.0638e+00,  7.0637e-01,  3.2142e-02,  ..., -9.5529e-02,\n",
       "           -3.9551e-01, -1.2817e+00],\n",
       "          [-1.6870e+00,  2.4137e-01, -1.2955e+00,  ...,  3.0448e-01,\n",
       "            3.7718e-01,  1.9741e-01],\n",
       "          [ 5.3172e-01,  1.8004e+00, -5.5910e-01,  ...,  2.8830e-02,\n",
       "           -1.2250e+00, -2.4092e-03]],\n",
       "\n",
       "         [[ 1.7825e+00, -9.0318e-01, -1.8246e+00,  ..., -1.3777e+00,\n",
       "            1.2892e-01,  8.4883e-01],\n",
       "          [-3.2886e-02,  2.0779e-01, -1.3716e+00,  ..., -1.3859e+00,\n",
       "            1.8670e+00,  2.5677e-01],\n",
       "          [ 3.4745e-01,  1.4416e-01, -1.5264e-01,  ..., -1.3292e-01,\n",
       "           -7.2847e-01,  1.8484e+00],\n",
       "          ...,\n",
       "          [-1.5014e+00, -2.9565e-01,  3.9286e-01,  ..., -8.7938e-01,\n",
       "           -7.4009e-02, -7.5017e-01],\n",
       "          [-1.6800e-01,  1.3853e+00, -6.7060e-01,  ...,  6.9014e-01,\n",
       "            1.1170e+00, -9.2529e-02],\n",
       "          [-9.0971e-01, -9.0004e-01,  2.5032e-01,  ..., -6.1480e-01,\n",
       "           -2.7941e-01,  1.0569e+00]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T14:01:55.936682Z",
     "start_time": "2023-12-29T14:01:52.562882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.7530, -10.6582],\n",
       "        [  9.7530, -10.6582]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPjnU81FiXBj0o3ws++XhAS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
