{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40883,
     "status": "ok",
     "timestamp": 1702456019505,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "HDipAI1KQbtE",
    "outputId": "5811967e-3719-4b3c-c6f2-daa6c3d0f765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms\n",
    "from google.colab import drive\n",
    "import torch.optim as opt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1702456767743,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "c83JmHCJiLBW"
   },
   "outputs": [],
   "source": [
    "class BLOCK(nn.Module) :\n",
    "  def __init__(self,inplanes:int, planes:int, stride:int, downsample=None) :\n",
    "    super(BLOCK,self).__init__() #繼承父類\n",
    "    self.conv1 = nn.Conv2d(inplanes,planes,3,stride,padding=1,bias=False) #子模塊第一層\n",
    "    self.bn1 = nn.BatchNorm2d(planes) #子模塊第一層標準化\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.conv2 = nn.Conv2d(planes,planes,3,stride=1,padding=1,bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "    self.stride = stride\n",
    "    self.downsample = downsample\n",
    "\n",
    "  def forward(self,x) :\n",
    "    identity = x\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "    if self.downsample is not None :\n",
    "      identity = self.downsample(x)\n",
    "    out = out + identity\n",
    "    out = self.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1702456772022,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "dWGWgUvtiA-_"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module) :\n",
    "  def __init__(self,lays:list,num_classes:int) :\n",
    "    super(ResNet,self).__init__()\n",
    "    self.inplanes = 64\n",
    "    # self.conv1 = nn.Conv2d(3,self.inplanes,7,stride=2,padding=3)\n",
    "    self.conv1 = nn.Conv2d(3,self.inplanes,3,stride=1,padding=1)\n",
    "    #稍微修改一下第一次的捲積操作，便於保留特徵\n",
    "    self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=1,padding=1) #後面池化操作進行刪除\n",
    "    self.lay1 = self._make_lay(64,lays[0],stride=1)\n",
    "    self.lay2 = self._make_lay(128,lays[1],stride=2)\n",
    "    self.lay3 = self._make_lay(256,lays[2],stride=2)\n",
    "    self.lay4 = self._make_lay(512,lays[3],stride=2)\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "  def _make_lay(self,planes:int,num_blocks:int,stride:int) -> nn.Sequential :\n",
    "    downsample = None\n",
    "    if stride != 1 or self.inplanes != planes:\n",
    "      downsample = nn.Sequential(nn.Conv2d(self.inplanes, planes, 1, stride=stride, bias=False), nn.BatchNorm2d(planes))\n",
    "    lays = []\n",
    "    lays.append(BLOCK(self.inplanes, planes, stride, downsample))\n",
    "    self.inplanes = planes\n",
    "    for i in range(num_blocks) :\n",
    "      lays.append(BLOCK(self.inplanes,planes,stride=1))\n",
    "    return nn.Sequential(*lays)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    # x = self.maxpool(x)\n",
    "\n",
    "    x = self.lay1(x)\n",
    "    x = self.lay2(x)\n",
    "    x = self.lay3(x)\n",
    "    x = self.lay4(x)\n",
    "\n",
    "    x = self.avgpool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702456776219,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "fYujmSK4h_NG"
   },
   "outputs": [],
   "source": [
    "def resnet18(num_classes)->ResNet :\n",
    "  model=ResNet([2, 2, 2, 2], num_classes)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702456266167,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "NRScuEVBF9WQ"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_CIFAR10_data_batch(batch_id = 1) :\n",
    "    file_dir = '/content/drive/MyDrive/cifar-10-batches-py/data_batch_' + str(batch_id)\n",
    "    dict_ = unpickle(file_dir)\n",
    "    img = dict_[b'data']\n",
    "    labels = dict_[b'labels']\n",
    "    return np.array(img),np.array(labels)\n",
    "\n",
    "class CIFAR10_Dataset(Dataset) :\n",
    "    def __init__(self,mode = \"train\"):\n",
    "        if mode == \"test\" :\n",
    "            data ,target = load_CIFAR10_data_batch(6)\n",
    "            self.data = data\n",
    "            self.target = target\n",
    "            self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.49139968 ,0.48215841, 0.44653091), std=(0.20220212, 0.19931542, 0.20086346))])\n",
    "        elif mode == \"train\" :\n",
    "            self.data ,self.target = load_CIFAR10_data_batch(1)\n",
    "            for i in range(2,6) :\n",
    "                temp_data ,temp_target = load_CIFAR10_data_batch(i)\n",
    "                self.data = np.concatenate([self.data,temp_data])\n",
    "                self.target = np.concatenate([self.target,temp_target])\n",
    "            self.transform = transforms.Compose([transforms.RandomCrop(32, padding=4),transforms.RandomHorizontalFlip(p=0.5),transforms.ToTensor(),transforms.Normalize(mean=(0.49139968 ,0.48215841, 0.44653091), std=(0.20220212, 0.19931542, 0.20086346))])\n",
    "        self.data = self.data.reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.target[idx]\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img = self.transform(img)\n",
    "        return img,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1561,
     "status": "ok",
     "timestamp": 1702456271202,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "LI7er2gCOezS"
   },
   "outputs": [],
   "source": [
    "train_data = CIFAR10_Dataset(\"train\")\n",
    "test_data = CIFAR10_Dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1702456784658,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "zRfhGHEhT21w"
   },
   "outputs": [],
   "source": [
    "resnet18_model = resnet18(num_classes=10) #返回一個類實例，然而類的實例會接受num_classes=10的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1702456788031,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "PbKAI1CSUNGA",
    "outputId": "fd7795f9-a126-4488-864a-d7630a5349f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "model = resnet18_model\n",
    "model.to(device)\n",
    "optimizer = opt.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.8)  # 每1个epoch学习率乘以0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2245646,
     "status": "ok",
     "timestamp": 1702459035511,
     "user": {
      "displayName": "Peter Stark",
      "userId": "05805658922587657421"
     },
     "user_tz": -480
    },
    "id": "Hn21UNSuY8xe",
    "outputId": "c8c738b8-32ea-49f2-9794-78149c10cd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5441 613.5042065382004\n",
      "0\n",
      "0.6543 421.63701379299164\n",
      "1\n",
      "0.6806 332.44990944862366\n",
      "2\n",
      "0.7378 273.3976976275444\n",
      "3\n",
      "0.7727 224.02515038847923\n",
      "4\n",
      "0.8292 194.26150715351105\n",
      "5\n",
      "0.8382 167.99492514133453\n",
      "6\n",
      "0.8483 147.98041181266308\n",
      "7\n",
      "0.8563 132.5680220425129\n",
      "8\n",
      "0.8719 117.62333180010319\n",
      "9\n",
      "0.8735 106.45362375676632\n",
      "10\n",
      "0.8788 95.961235396564\n",
      "11\n",
      "0.8866 87.66079300642014\n",
      "12\n",
      "0.8848 79.27086404711008\n",
      "13\n",
      "0.8896 74.10963126271963\n",
      "14\n",
      "0.889 68.21156156808138\n",
      "15\n",
      "0.8922 64.41388633474708\n",
      "16\n",
      "0.892 61.40816478058696\n",
      "17\n",
      "0.8942 57.92977983132005\n",
      "18\n",
      "0.8946 55.49798947945237\n",
      "19\n",
      "0.8961 54.162969287484884\n",
      "20\n",
      "0.8951 53.476618794724345\n",
      "21\n",
      "0.8972 52.32555706053972\n",
      "22\n",
      "0.8956 51.64264262840152\n",
      "23\n",
      "0.8949 50.43897262215614\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # 定义损失函数\n",
    "criterion = criterion.to(device)\n",
    "num_epochs = 25  # 设置训练轮数\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()  # 设置模型为训练模式\n",
    "  running_loss = 0.0\n",
    "  for i,(inputs,labels) in enumerate(train_loader):\n",
    "      inputs, labels = inputs.to(device), labels.to(device)  # 将输入和标签移至设备\n",
    "      optimizer.zero_grad()  # 清零梯度\n",
    "      outputs = model(inputs)  # 前向传播\n",
    "      loss = criterion(outputs, labels)  # 计算损失\n",
    "      loss.backward()  # 反向传播:\n",
    "      optimizer.step()  # 更新模型参数\n",
    "      running_loss += loss.item()  # 累加损失\n",
    "  scheduler.step()\n",
    "  model.eval()\n",
    "  acc = 0\n",
    "  for j,(inputs,labels) in enumerate(test_loader):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)  # 将输入和标签移至设备\n",
    "    outputs = model(inputs)\n",
    "    for k in range(len(outputs)) :\n",
    "      s = torch.argmax(outputs[k])\n",
    "      if s == labels[k] :\n",
    "        acc +=1\n",
    "  print(acc/len(test_data.data),running_loss)\n",
    "  print(epoch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
